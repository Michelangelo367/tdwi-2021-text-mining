{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Reddit Autos Selfposts<div class=\"tocSkip\">\n",
    "    \n",
    "&copy; Jens Albrecht, 2021\n",
    "    \n",
    "This notebook can be freely copied and modified.  \n",
    "Attribution, however, is highly appreciated.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also: \n",
    "\n",
    "Albrecht, Ramachandran, Winkler: **Blueprints for Text Analytics in Python** (O'Reilly 2020)  \n",
    "Chapter 6: [Text Classification Algorithms](https://learning.oreilly.com/library/view/blueprints-for-text/9781492074076/ch06.html#ch-classification) + [Link to Github](https://github.com/blueprints-for-text-analytics-python/blueprints-text/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup<div class='tocSkip'/>\n",
    "\n",
    "Set directory locations. If working on Google Colab: copy files and install required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:49.459462Z",
     "start_time": "2021-06-17T17:05:49.442000Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    GIT_ROOT = 'https://github.com/jsalbr/tdwi-2021-text-mining/raw/main'\n",
    "    os.system(f'wget {GIT_ROOT}/notebooks/setup.py')\n",
    "\n",
    "%run -i setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Python Settings<div class=\"tocSkip\"/>\n",
    "\n",
    "Common imports, defaults for formatting in Matplotlib, Pandas etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:55.545068Z",
     "start_time": "2021-06-17T17:05:49.462095Z"
    }
   },
   "outputs": [],
   "source": [
    "%run \"$BASE_DIR/notebooks/settings.py\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "# to print output of all statements and not just the last\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# otherwise text between $ signs will be interpreted as formula and printed in italic\n",
    "pd.set_option('display.html.use_mathjax', False)\n",
    "pd.options.plotting.backend = \"matplotlib\"\n",
    "\n",
    "# path to import blueprints packages\n",
    "sys.path.append('./packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing Data for Machine Learning\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:56.122377Z",
     "start_time": "2021-06-17T17:05:55.547632Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{BASE_DIR}/data/reddit-autos-selfposts-prepared.csv\", sep=\";\", decimal=\".\")\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:56.727345Z",
     "start_time": "2021-06-17T17:05:56.124701Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"reddit-autos-selfposts-prepared.csv\", sep=\";\", decimal=\".\")\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:56.781134Z",
     "start_time": "2021-06-17T17:05:56.729293Z"
    }
   },
   "outputs": [],
   "source": [
    "# set display column width unlimited to show full text\n",
    "pd.set_option('max_colwidth', -1)\n",
    "\n",
    "df.sample(5)\n",
    "\n",
    "# reset display column width to 30\n",
    "pd.reset_option('max_colwidth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Label\n",
    "\n",
    "Store the label in a variable to make modifications easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:56.816836Z",
     "start_time": "2021-06-17T17:05:56.783374Z"
    }
   },
   "outputs": [],
   "source": [
    "label = 'subreddit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:56.854999Z",
     "start_time": "2021-06-17T17:05:56.819240Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df[label].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:57.110998Z",
     "start_time": "2021-06-17T17:05:56.858937Z"
    }
   },
   "outputs": [],
   "source": [
    "df[label].value_counts().plot(kind='barh').invert_yaxis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization\n",
    "\n",
    "Here we use scikit-learn's TF-IDF vectorizers for bag-of-words vectorization, i.e. creating the TF or TF-IDF matrix.\n",
    "\n",
    "http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn-feature-extraction-text-countvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:57.143542Z",
     "start_time": "2021-06-17T17:05:57.113126Z"
    }
   },
   "outputs": [],
   "source": [
    "# choose text column for vectorization\n",
    "text_col = 'lemmas'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Term-Frequency Matrix (Counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:57.864910Z",
     "start_time": "2021-06-17T17:05:57.146078Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# learn vocabulary for all data\n",
    "count_vect = CountVectorizer(ngram_range=(1, 1), \n",
    "                             min_df=1, \n",
    "                             max_df=1.0, \n",
    "                             lowercase=True,\n",
    "                             stop_words=None,\n",
    "                             tokenizer=str.split)\n",
    "\n",
    "# alternatively: only nouns or nouns+adjs+verbs\n",
    "X_tf = count_vect.fit_transform(df[text_col])\n",
    "\n",
    "type(X_tf)\n",
    "X_tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional: Play with hyperparameters i.e.\n",
    "\n",
    "  * `ngram_range=(1, 2)` to include bigrams\n",
    "  * `max_df=0.5` to exclude words occuring in more than 50% of the documents\n",
    "  * `min_df=2` to include only words occuring in at least 2 documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF-Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:57.961973Z",
     "start_time": "2021-06-17T17:05:57.866989Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_vect = TfidfTransformer()\n",
    "\n",
    "X_tfidf = tfidf_vect.fit_transform(X_tf)\n",
    "\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T18:34:27.938687Z",
     "start_time": "2020-04-23T18:34:27.810687Z"
    }
   },
   "source": [
    "Choose data matrix `X` and label vector `y` for training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:57.992210Z",
     "start_time": "2021-06-17T17:05:57.965732Z"
    }
   },
   "outputs": [],
   "source": [
    "# alternatively: X = X_tf\n",
    "X = X_tfidf\n",
    "\n",
    "# define label vector\n",
    "y = df[label]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now split with `train_test_split()`.\n",
    "\n",
    "Recommendation: use `stratify=y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:58.056708Z",
     "start_time": "2021-06-17T17:05:57.994245Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# define holdout\n",
    "test_size = 0.2\n",
    "\n",
    "if test_size > 0.0:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                        test_size=test_size,\n",
    "                                                        stratify = y,\n",
    "                                                        random_state=43\n",
    "                                                       )\n",
    "else:\n",
    "    X_train, X_test, y_train, y_test = X, None, y, None\n",
    "    \n",
    "    \n",
    "print(\"Trainigsmatrix:\", X_train.shape)\n",
    "print(\"Testmatrix:    \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store information about train/test records in data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:58.092328Z",
     "start_time": "2021-06-17T17:05:58.059895Z"
    }
   },
   "outputs": [],
   "source": [
    "df['train_test'] = pd.Series(df.index.isin(y_test.index)).map(lambda x: 'Test' if x else 'Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:58.133762Z",
     "start_time": "2021-06-17T17:05:58.094305Z"
    }
   },
   "outputs": [],
   "source": [
    "df['train_test'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stratification enforces 80:20 split even within classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:58.204415Z",
     "start_time": "2021-06-17T17:05:58.135528Z"
    }
   },
   "outputs": [],
   "source": [
    "df[[label, 'train_test']].pivot_table(index=label, columns='train_test', aggfunc=len, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine\n",
    "\n",
    "We use the Support Vector Machine for training which works excellent for TF-IDF vectors. Fastest implementation is `LinearSVC`, but allows only linear kernels. Alternatively use `SGDClassifier`.\n",
    "To use a different classifier like logistic regression, just uncomment the respective lines.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.LinearSVC.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:59.394056Z",
     "start_time": "2021-06-17T17:05:58.206344Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "print(f'Training on column {label}')\n",
    "\n",
    "clf = LinearSVC(C=1.0)\n",
    "# clf = SGDClassifier(loss='hinge', max_iter=1000, tol=1e-3, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train);\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extremely fast, right!?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "Apply classifier to test data with `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:59.464058Z",
     "start_time": "2021-06-17T17:05:59.396231Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "print(f\"Classifier: {clf.__class__}\\n\")\n",
    "\n",
    "print('Accuracy Summary')\n",
    "print('================')\n",
    "\n",
    "print(f'Test:    {accuracy_score(y_test, y_test_pred)*100:6.2f}%')\n",
    "print(f'Train:   {accuracy_score(y_train, y_train_pred)*100:6.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad for a 12-class classifier!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$Accuracy = \\frac{\\text{number of correctly classified data points}}{\\text{all data points}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:59.498940Z",
     "start_time": "2021-06-17T17:05:59.465946Z"
    }
   },
   "outputs": [],
   "source": [
    "sum(y_test == y_test_pred)/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-04-23T19:03:31.981480Z",
     "start_time": "2020-04-23T19:03:31.843477Z"
    }
   },
   "source": [
    "Looking at the per-class metrics with `classification_report`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:05:59.658532Z",
     "start_time": "2021-06-17T17:05:59.500984Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Classification Report\")\n",
    "print(\"=====================\")\n",
    "print(classification_report(y_true=y_test, y_pred=y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And on the training data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:00.190913Z",
     "start_time": "2021-06-17T17:05:59.660704Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Classification Report\")\n",
    "print(\"=====================\")\n",
    "print(classification_report(y_true=y_train, y_pred=y_train_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "\n",
    "Visualizing the `confusion_matrix` by `sns.heatmap`.\n",
    "\n",
    "Not surprisingly, the generic category \"AskMechanics\" is frequently confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:00.890735Z",
     "start_time": "2021-06-17T17:06:00.193864Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# label names - specifies order in confusion matrix\n",
    "label_names = sorted(y_test.unique())\n",
    "\n",
    "# scale figure size depending on number of categories\n",
    "fsize = len(label_names)/2\n",
    "sns.set(font_scale=1)\n",
    "\n",
    "conf_mat = confusion_matrix(y_test, y_test_pred, labels=label_names)\n",
    "\n",
    "_ = fig, ax = plt.subplots(figsize=(fsize, fsize))\n",
    "_ = sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, \n",
    "                xticklabels=label_names, yticklabels=label_names)\n",
    "_ = plt.ylabel(\"Actual\")\n",
    "_ = plt.xlabel(\"Predicted\")\n",
    "_ = ax.set_title(f\"Confusion Matrix for {label}\", fontsize=14)\n",
    "\n",
    "sns.set(font_scale=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking misclassified Data\n",
    "\n",
    "Looking at samples of misclassified and correctly classified data.\n",
    "\n",
    "Add the predictions to the dataframe to simplify the analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:00.926782Z",
     "start_time": "2021-06-17T17:06:00.895251Z"
    }
   },
   "outputs": [],
   "source": [
    "# transform prediction vectors to pandas series with correct indexes\n",
    "y_test_pred = pd.Series(y_test_pred, index=y_test.index)\n",
    "y_train_pred = pd.Series(y_train_pred, index=y_train.index)\n",
    "\n",
    "df['pred'] = pd.concat([y_test_pred, y_train_pred])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T07:29:54.726168Z",
     "start_time": "2021-06-17T07:29:54.703841Z"
    }
   },
   "source": [
    "Check sample of misclassified data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:01.004751Z",
     "start_time": "2021-06-17T17:06:00.930488Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# adjust size of visible columns\n",
    "pd.set_option('max_colwidth', 3000)\n",
    "\n",
    "df.query(f'train_test==\"Test\" and {label}!=pred')[[label, 'pred', 'text', text_col]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check sample of correctly classified data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:01.057434Z",
     "start_time": "2021-06-17T17:06:01.007904Z"
    }
   },
   "outputs": [],
   "source": [
    "df.query(f'train_test==\"Test\" and {label}==pred')[[label, 'pred', 'text', text_col]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DataFrame with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:03.042281Z",
     "start_time": "2021-06-17T17:06:01.060653Z"
    }
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"reddit-autos-selfposts-predicted.csv\", sep=\";\", decimal=\".\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explaining the Classifier\n",
    "\n",
    "### Measuring Feature Importance\n",
    "\n",
    "The coefficients of the SVM can be used to display the feature (=word) importance per class, positively and negatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:03.078274Z",
     "start_time": "2021-06-17T17:06:03.044521Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_coefficients(classifier, vect, top_features=20):\n",
    "\n",
    "    # get the feature names from the vectorizer\n",
    "    feature_names = np.array(vect.get_feature_names())\n",
    "\n",
    "    for i, category in enumerate(clf.classes_):\n",
    "\n",
    "        # get class coefficients\n",
    "        coef = classifier.coef_[i]\n",
    "\n",
    "        # get the top and worst features\n",
    "        top_pos_coefs = np.argsort(coef)[-top_features:]\n",
    "        top_neg_coefs = np.argsort(coef)[:top_features]\n",
    "        top_coefs = np.hstack([top_neg_coefs, top_pos_coefs])[::-1]\n",
    "\n",
    "        # create plot\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.title(f'Coefficients for category \"{category}\"')\n",
    "        colors = ['xkcd:green' if c > 0 else 'xkcd:red' for c in coef[top_coefs]]\n",
    "        plt.bar(np.arange(2*top_features), coef[top_coefs], color=colors)\n",
    "\n",
    "        feature_names[top_coefs]\n",
    "\n",
    "        np.arange(0, 2 * top_features)\n",
    "\n",
    "        plt.xticks(np.arange(0, 2 * top_features), feature_names[top_coefs], rotation=90, ha='center')\n",
    "        plt.grid(linestyle='dashed')\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:10.134858Z",
     "start_time": "2021-06-17T17:06:03.080513Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_coefficients(clf, count_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier Explanation with LIME\n",
    "\n",
    "We need a classifier with prediction probabilities. `LinearSVC` does not yield these. We use Logistic Regression instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:39.105060Z",
     "start_time": "2021-06-17T17:06:10.137244Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "\n",
    "print(f'Training on column {label}')\n",
    "\n",
    "# log loss gives logistic regression\n",
    "# clf = SGDClassifier(loss='log', max_iter=1000, tol=1e-3, random_state=42)\n",
    "clf = LogisticRegression() # C=1.0, class_weight='balanced')\n",
    "\n",
    "clf.fit(X_train, y_train);\n",
    "\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:39.278312Z",
     "start_time": "2021-06-17T17:06:39.113394Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test_pred = clf.predict(X_test)\n",
    "y_train_pred = clf.predict(X_train)\n",
    "\n",
    "print(f\"Classifier: {clf.__class__}\\n\")\n",
    "\n",
    "print('Accuracy Summary')\n",
    "print('================')\n",
    "\n",
    "print(f'Test:    {accuracy_score(y_test, y_test_pred)*100:6.2f}%')\n",
    "print(f'Train:   {accuracy_score(y_train, y_train_pred)*100:6.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:39.322570Z",
     "start_time": "2021-06-17T17:06:39.281043Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "pipeline = make_pipeline(count_vect, tfidf_vect, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:39.368581Z",
     "start_time": "2021-06-17T17:06:39.325191Z"
    }
   },
   "outputs": [],
   "source": [
    "# use lemmas only here, because model is trained on lemmas\n",
    "samples = [\n",
    "    \"BMW great\", \n",
    "    \"Electric charge take long\"\n",
    "]\n",
    "\n",
    "pred = pipeline.predict_proba(samples)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:39.410458Z",
     "start_time": "2021-06-17T17:06:39.371957Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.options.display.float_format = '{:.4f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:39.465697Z",
     "start_time": "2021-06-17T17:06:39.412694Z"
    }
   },
   "outputs": [],
   "source": [
    "columns = [f\"Sample {i+1}\" for i in range(pred.shape[0])]\n",
    "\n",
    "pred_df = pd.DataFrame(pred.T, index=clf.classes_, columns=columns)\n",
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:39.505972Z",
     "start_time": "2021-06-17T17:06:39.469178Z"
    }
   },
   "outputs": [],
   "source": [
    "# adjust size of visible columns\n",
    "pd.set_option('max_colwidth', 3000)\n",
    "\n",
    "#df.query(f'train_test==\"Test\" and {label}!=pred')[[label, 'pred', 'text', text_col]].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example: Predicted is \"teslamotors\", but correct is \"Toyota\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:39.551545Z",
     "start_time": "2021-06-17T17:06:39.508534Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[7468].to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:39.591146Z",
     "start_time": "2021-06-17T17:06:39.554164Z"
    }
   },
   "outputs": [],
   "source": [
    "text = df.iloc[7468].lemmas\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:44.302733Z",
     "start_time": "2021-06-17T17:06:39.592975Z"
    }
   },
   "outputs": [],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=clf.classes_)\n",
    "\n",
    "exp = explainer.explain_instance(text, pipeline.predict_proba, num_features=6, top_labels=3)\n",
    "\n",
    "print([exp.class_names[i] for i in exp.available_labels()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:06:44.455345Z",
     "start_time": "2021-06-17T17:06:44.317825Z"
    }
   },
   "outputs": [],
   "source": [
    "exp.show_in_notebook(text=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ENDE <div class=\"tocSkip\">"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "236.981px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
