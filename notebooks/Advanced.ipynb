{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis with BERT<div class=\"tocSkip\">\n",
    "    \n",
    "&copy; Jens Albrecht, 2021\n",
    "    \n",
    "This notebook can be freely copied and modified.  \n",
    "Attribution, however, is highly appreciated.\n",
    "\n",
    "<hr/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See also: \n",
    "\n",
    "Albrecht, Ramachandran, Winkler: **Blueprints for Text Analytics in Python** (O'Reilly 2020)  \n",
    "Chapter 11: [Performing Sentiment Analysis on Text Data](https://learning.oreilly.com/library/view/blueprints-for-text/9781492074076/ch11.html#ch-sentiment) + [Link to Github](https://github.com/blueprints-for-text-analytics-python/blueprints-text/blob/master/README.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup<div class='tocSkip'/>\n",
    "\n",
    "Set directory locations. If working on Google Colab: copy files and install required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:29:48.967409Z",
     "start_time": "2021-06-18T12:29:48.942105Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "ON_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if ON_COLAB:\n",
    "    GIT_ROOT = 'https://github.com/jsalbr/tdwi-2021-text-mining/raw/main'\n",
    "    os.system(f'wget {GIT_ROOT}/notebooks/setup.py')\n",
    "\n",
    "%run -i setup.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Python Settings<div class=\"tocSkip\"/>\n",
    "\n",
    "Common imports, defaults for formatting in Matplotlib, Pandas etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:36:33.962514Z",
     "start_time": "2021-06-18T12:36:33.876880Z"
    }
   },
   "outputs": [],
   "source": [
    "%run \"$BASE_DIR/notebooks/settings.py\"\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'png'\n",
    "\n",
    "# to print output of all statements and not just the last\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "# otherwise text between $ signs will be interpreted as formula and printed in italic\n",
    "pd.set_option('display.html.use_mathjax', False)\n",
    "pd.options.plotting.backend = \"matplotlib\"\n",
    "\n",
    "# path to import blueprints packages\n",
    "sys.path.append(f'{BASE_DIR}/packages')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:29:57.671136Z",
     "start_time": "2021-06-18T12:29:56.868003Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{BASE_DIR}/data/reddit-autos-selfposts-prepared.csv\", sep=\";\", decimal=\".\")\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings\n",
    "\n",
    "Let the following code run to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:34:03.223178Z",
     "start_time": "2021-06-18T12:32:18.118710Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# sents = df['lemmas'].str.lower().str.split() \n",
    "# model = Word2Vec(sents, vector_size=100, window=30, sg=1)\n",
    "# model.wv.save_word2vec_format('w2v_autos_100_30_sg.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:44:54.896779Z",
     "start_time": "2021-06-18T12:44:54.691646Z"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model = KeyedVectors.load_word2vec_format(f'{BASE_DIR}/data/w2v_autos_100_30_sg.bin', binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity Queries to Explore a Domain Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model with large vector size 30 favors similar terms that often cooccur with the search word (syntagmatic relations):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:50:00.496446Z",
     "start_time": "2021-06-18T12:50:00.398982Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.most_similar('audi', topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works great for associative questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:47:05.198284Z",
     "start_time": "2021-06-18T12:47:05.092117Z"
    }
   },
   "outputs": [],
   "source": [
    "model.most_similar(positive=['x5', 'audi'], negative=['bmw'], topn=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:36:51.442148Z",
     "start_time": "2021-06-18T12:36:37.492554Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from blueprints.embeddings import plot_embeddings\n",
    "\n",
    "search = ['ford', 'bmw', 'toyota', 'tesla', 'audi', 'mercedes', 'hyundai']\n",
    "\n",
    "plot_embeddings(model, search, topn=30, n_dims=3, \n",
    "    algo='umap', n_neighbors=15, min_dist=.1, spread=40, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:39:17.510381Z",
     "start_time": "2021-06-18T12:39:16.938044Z"
    }
   },
   "outputs": [],
   "source": [
    "from blueprints.embeddings import sim_tree, plot_tree\n",
    "\n",
    "graph = sim_tree(model, 'sparkplug', top_n=8, max_dist=2)\n",
    "plot_tree(graph, node_size=500, font_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis Using Huggingface Transformers\n",
    "\n",
    "Links: \n",
    "  * [Transformers Library from Hugging Face](https://huggingface.co/transformers)\n",
    "  * [Transformers Quick Tour](https://huggingface.co/transformers/quicktour.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Model for Sentiment Analysis\n",
    "\n",
    "For a list of models see [Hugging Face Model Hub](https://huggingface.co/models).\n",
    "\n",
    "Model download takes a moment ...\n",
    "\n",
    "It's stored in `~/.cache/huggingface/transformers` (see [Huggingface documentation](https://huggingface.co/docs/datasets/installation.html#caching-datasets-and-metrics))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:10:14.870882Z",
     "start_time": "2021-06-18T09:10:08.125792Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# classifier = pipeline('sentiment-analysis', model='distilbert-base-uncased-finetuned-sst-2-english')\n",
    "classifier = pipeline('sentiment-analysis', model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:10:14.909296Z",
     "start_time": "2021-06-18T09:10:14.873232Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model was trained on product reviews in five languages. Predicts ratings from 1 to 5 stars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:10:15.102101Z",
     "start_time": "2021-06-18T09:10:14.911668Z"
    }
   },
   "outputs": [],
   "source": [
    "sents = [\n",
    "  'We are very happy to show you the ðŸ¤— Transformers library.',\n",
    "  'The weather today is not really what I expected.'\n",
    "]\n",
    "\n",
    "classifier(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aspect-based Sentiment Analysis\n",
    "\n",
    "Check sentiment for the aspect \"charging\" in Tesla subreddit.\n",
    "\n",
    "Look for token 'charge' in subreddit 'teslamotors' and exclude questions ('?')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T12:52:53.192273Z",
     "start_time": "2021-06-18T12:52:53.034784Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 3000)\n",
    "\n",
    "senti_df = df[\n",
    "    (df['lemmas'].str.len() < 400) &\n",
    "    df['lemmas'].str.lower().str.contains('charge') &\n",
    "    (~df['text'].str.contains('\\?')) &\n",
    "    (df['subreddit']=='teslamotors')][['text']].sample(20)\n",
    "senti_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:39:31.483796Z",
     "start_time": "2021-06-17T17:39:31.420622Z"
    }
   },
   "source": [
    "Add sentiment prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-17T17:52:41.616898Z",
     "start_time": "2021-06-17T17:52:39.207463Z"
    }
   },
   "outputs": [],
   "source": [
    "senti_df.join(pd.DataFrame(classifier(list(senti_df['text'].str.lower()))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question Answering\n",
    "\n",
    "Training based on Stanford Question Answering Dataset (SQuAD 2.0).  \n",
    "\n",
    "See\n",
    "  * https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/European_Union_law.html\n",
    "  * [Huggingface documentation for QA](https://huggingface.co/transformers/usage.html#extractive-question-answering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:10:23.692685Z",
     "start_time": "2021-06-18T09:10:18.192609Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "context = r\"\"\"\n",
    "Extractive Question Answering is the task of extracting an answer from a text given a question. An example of a\n",
    "question answering dataset is the SQuAD dataset, which is entirely based on that task. If you would like to fine-tune\n",
    "a model on a SQuAD task, you may leverage the `run_squad.py`.\n",
    "\"\"\"\n",
    "\n",
    "question = \"What is extractive question answering?\"\n",
    "answer = qa_model(question=question, context=context)\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", answer['answer'], f\"(confidence: {answer['score']:.2f})\\n\")\n",
    "\n",
    "question = \"What is a good example of a question answering dataset?\"\n",
    "answer = qa_model(question=question, context=context)\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", answer['answer'], f\"(confidence: {answer['score']:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples from [Game of Thrones Wiki](https://gameofthrones.fandom.com/wiki):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-18T09:10:29.494859Z",
     "start_time": "2021-06-18T09:10:23.816099Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "qa_model = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
    "\n",
    "context = \"\"\"\n",
    "Bran is the fourth child and second son of Lady Catelyn and Lord Ned\n",
    "Stark. Ned is the head of House Stark, Lord Paramount of the North,\n",
    "and Warden of the North to King Robert Baratheon. The North is one of\n",
    "the constituent regions of the Seven Kingdoms and House Stark is one\n",
    "of the Great Houses of the realm. House Stark rules the region from\n",
    "their seat of Winterfell.\n",
    "\n",
    "Winterfell is the capital of the Kingdom of the North and the seat and \n",
    "the ancestral home of the royal House Stark. It is a very large castle \n",
    "located at the center of the North, from where the head of House Stark \n",
    "rules over his or her people. \"\"\"\n",
    "\n",
    "question = \"Who is Bran?\"\n",
    "answer = qa_model(question=question, context=context)\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", answer['answer'], f\"(confidence: {answer['score']:.2f})\\n\")\n",
    "\n",
    "question = \"What is Winterfell?\"\n",
    "answer = qa_model(question=question, context=context)\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", answer['answer'], f\"(confidence: {answer['score']:.2f})\\n\")\n",
    "\n",
    "question = \"Where is Winterfell located?\"\n",
    "answer = qa_model(question=question, context=context)\n",
    "print(\"Q:\", question)\n",
    "print(\"A:\", answer['answer'], f\"(confidence: {answer['score']:.2f})\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "822px",
    "left": "36px",
    "top": "132.8px",
    "width": "220.656px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
